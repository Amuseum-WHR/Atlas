{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "# opt的使用请参照auxiliary/argument_parser.py中opt的说明\n",
    "opt = {\"normalization\": \"UnitBall\",\n",
    "            \"class_choice\": [\"plane\"], \n",
    "            \"SVR\": True, \n",
    "            \"sample\": True, \n",
    "            \"npoints\": 2500, \n",
    "            \"number_points\": 2500, \n",
    "            \"shapenet13\": True, \n",
    "            \"demo\": False, \n",
    "            \"data_augmentation_axis_rotation\": True,\n",
    "            \"data_augmentation_random_flips\": False, \n",
    "            \"batch_size\": 32, \n",
    "            \"workers\": 0, \n",
    "            \"batch_size_test\": 32, \n",
    "            \"random_translation\": False, \n",
    "            \"anisotropic_scaling\": False, \n",
    "            \"random_rotation\": False, # 以上为加载dataset需要\n",
    "            \"multi_gpu\": [0],\n",
    "            \"bottleneck_size\": 1024,\n",
    "            \"nb_primitives\": 1,\n",
    "            \"number_points\": 2500,\n",
    "            \"number_points_eval\": 2500,\n",
    "            \"remove_all_batchNorms\": False,\n",
    "            \"template_type\": \"SPHERE\",\n",
    "            \"dim_template\": 3,\n",
    "            \"hidden_neurons\": 512,\n",
    "            \"num_layers\": 2,\n",
    "            \"activation\" : \"relu\",\n",
    "            \"reload_model_path\": \"\",\n",
    "            \"reload_decoder_path\": \"\",\n",
    "            \"train_only_encoder\": False,\n",
    "            \"lrate\": 0.001,\n",
    "            \"no_learning\": False,\n",
    "            \"nepoch\": 150,\n",
    "            \"reload_optimizer_path\": \"\", #下面两个是log信息\n",
    "            \"log_path\": \"log\",\n",
    "            \"name\": \"test_code\",\n",
    "            \"loop_per_epoch\": 1,\n",
    "            \"lr_decay_1\": 120,\n",
    "            \"lr_decay_2\": 140,\n",
    "            \"lr_decay_3\": 145,\n",
    "            \"visdom_port\": 8890,\n",
    "            \"http_port\": 8891,\n",
    "            \"env\": \"Atlasnet\",\n",
    "            \"dir_name\": \"\",\n",
    "            \"demo\": False}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDataset normalization : UnitBall\u001b[0m\n",
      "\u001b[31mCreate Shapenet Dataset...\u001b[0m\n",
      "['02691156', '02747177', '02773838', '02801938', '02808440', '02818832', '02828884', '02834778', '02843684', '02858304', '02871439', '02876657', '02880940', '02924116', '02933112', '02942699', '02946921', '02954340', '02958343', '02992529', '03001627', '03046257', '03085013', '03207941', '03211117', '03261776', '03325088', '03337140', '03467517', '03513137', '03593526', '03624134', '03636649', '03642806', '03691459', '03710193', '03759954', '03761084', '03790512', '03797390', '03928116', '03938244', '03948459', '03991062', '04004475', '04074963', '04090263', '04099429', '04225987', '04256520', '04330267', '04379243', '04401088', '04460130', '04468005', '04530566', '04554684']\n",
      "    category \u001b[33m02691156\u001b[0m  \u001b[36mairplane\u001b[0m Number Files :\u001b[33m3236\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/env1/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    category \u001b[33m02828884\u001b[0m  \u001b[36mbench\u001b[0m Number Files :\u001b[33m1452\u001b[0m\n",
      "    category \u001b[33m02933112\u001b[0m  \u001b[36mcabinet\u001b[0m Number Files :\u001b[33m1257\u001b[0m\n",
      "    category \u001b[33m02958343\u001b[0m  \u001b[36mcar\u001b[0m Number Files :\u001b[33m5996\u001b[0m\n",
      "    category \u001b[33m03001627\u001b[0m  \u001b[36mchair\u001b[0m Number Files :\u001b[33m5422\u001b[0m\n",
      "    category \u001b[33m03211117\u001b[0m  \u001b[36mdisplay\u001b[0m Number Files :\u001b[33m876\u001b[0m\n",
      "    category \u001b[33m03636649\u001b[0m  \u001b[36mlamp\u001b[0m Number Files :\u001b[33m1854\u001b[0m\n",
      "    category \u001b[33m03691459\u001b[0m  \u001b[36mloudspeaker\u001b[0m Number Files :\u001b[33m1294\u001b[0m\n",
      "    category \u001b[33m04090263\u001b[0m  \u001b[36mrifle\u001b[0m Number Files :\u001b[33m1897\u001b[0m\n",
      "    category \u001b[33m04256520\u001b[0m  \u001b[36msofa\u001b[0m Number Files :\u001b[33m2538\u001b[0m\n",
      "    category \u001b[33m04379243\u001b[0m  \u001b[36mtable\u001b[0m Number Files :\u001b[33m6807\u001b[0m\n",
      "    category \u001b[33m04401088\u001b[0m  \u001b[36mtelephone\u001b[0m Number Files :\u001b[33m841\u001b[0m\n",
      "    category \u001b[33m04530566\u001b[0m  \u001b[36mvessel\u001b[0m Number Files :\u001b[33m1551\u001b[0m\n",
      "\u001b[31mReload dataset : /mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/cache/UnitBallTrueairplane_bench_cabinet_car_chair_display_lamp_loudspeaker_rifle_sofa_table_telephone_vessel\u001b[0m\n",
      "\u001b[31mDataset Size: 11674\u001b[0m\n",
      "\u001b[31mDataset normalization : UnitBall\u001b[0m\n",
      "\u001b[31mCreate Shapenet Dataset...\u001b[0m\n",
      "['02691156', '02747177', '02773838', '02801938', '02808440', '02818832', '02828884', '02834778', '02843684', '02858304', '02871439', '02876657', '02880940', '02924116', '02933112', '02942699', '02946921', '02954340', '02958343', '02992529', '03001627', '03046257', '03085013', '03207941', '03211117', '03261776', '03325088', '03337140', '03467517', '03513137', '03593526', '03624134', '03636649', '03642806', '03691459', '03710193', '03759954', '03761084', '03790512', '03797390', '03928116', '03938244', '03948459', '03991062', '04004475', '04074963', '04090263', '04099429', '04225987', '04256520', '04330267', '04379243', '04401088', '04460130', '04468005', '04530566', '04554684']\n",
      "    category \u001b[33m02691156\u001b[0m  \u001b[36mairplane\u001b[0m Number Files :\u001b[33m809\u001b[0m\n",
      "    category \u001b[33m02828884\u001b[0m  \u001b[36mbench\u001b[0m Number Files :\u001b[33m364\u001b[0m\n",
      "    category \u001b[33m02933112\u001b[0m  \u001b[36mcabinet\u001b[0m Number Files :\u001b[33m315\u001b[0m\n",
      "    category \u001b[33m02958343\u001b[0m  \u001b[36mcar\u001b[0m Number Files :\u001b[33m1500\u001b[0m\n",
      "    category \u001b[33m03001627\u001b[0m  \u001b[36mchair\u001b[0m Number Files :\u001b[33m1356\u001b[0m\n",
      "    category \u001b[33m03211117\u001b[0m  \u001b[36mdisplay\u001b[0m Number Files :\u001b[33m219\u001b[0m\n",
      "    category \u001b[33m03636649\u001b[0m  \u001b[36mlamp\u001b[0m Number Files :\u001b[33m464\u001b[0m\n",
      "    category \u001b[33m03691459\u001b[0m  \u001b[36mloudspeaker\u001b[0m Number Files :\u001b[33m324\u001b[0m\n",
      "    category \u001b[33m04090263\u001b[0m  \u001b[36mrifle\u001b[0m Number Files :\u001b[33m475\u001b[0m\n",
      "    category \u001b[33m04256520\u001b[0m  \u001b[36msofa\u001b[0m Number Files :\u001b[33m635\u001b[0m\n",
      "    category \u001b[33m04379243\u001b[0m  \u001b[36mtable\u001b[0m Number Files :\u001b[33m1702\u001b[0m\n",
      "    category \u001b[33m04401088\u001b[0m  \u001b[36mtelephone\u001b[0m Number Files :\u001b[33m211\u001b[0m\n",
      "    category \u001b[33m04530566\u001b[0m  \u001b[36mvessel\u001b[0m Number Files :\u001b[33m388\u001b[0m\n",
      "\u001b[31mReload dataset : /mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/cache/UnitBallFalseairplane_bench_cabinet_car_chair_display_lamp_loudspeaker_rifle_sofa_table_telephone_vessel\u001b[0m\n",
      "\u001b[31mDataset Size: 2921\u001b[0m\n",
      "hello\n",
      "{'pointcloud_path': '/mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/ShapeNetV1PointCloud/02691156/103c9e43cdf6501c62b600da24e0965.points.ply.npy', 'image_path': '/mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/ShapeNetV1Renderings/02691156/103c9e43cdf6501c62b600da24e0965/rendering', 'name': '103c9e43cdf6501c62b600da24e0965.points.ply.npy', 'category': '02691156', 'points': tensor([[ 0.1870, -0.0730,  0.3077],\n",
      "        [-0.1446, -0.0831, -0.0074],\n",
      "        [ 0.5469, -0.0556, -0.0797],\n",
      "        ...,\n",
      "        [ 0.5984, -0.0409, -0.0888],\n",
      "        [ 0.1349, -0.0081,  0.2648],\n",
      "        [-0.3139, -0.0703,  0.0142]]), 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])}\n"
     ]
    }
   ],
   "source": [
    "from dataset.trainer_dataset import TrainerDataset\n",
    "Dataset = TrainerDataset()\n",
    "Dataset.opt = EasyDict(opt)\n",
    "Dataset.build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意metro部分需要修改地址\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pymesh\n",
    "from training.trainer_loss import TrainerLoss\n",
    "from model.trainer_model import TrainerModel\n",
    "from dataset.trainer_dataset import TrainerDataset\n",
    "from training.trainer_iteration import TrainerIteration\n",
    "from dataset.trainer_dataset import TrainerDataset\n",
    "import dataset.mesh_processor as mesh_processor\n",
    "from termcolor import colored\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class Trainer(TrainerLoss, TrainerIteration, TrainerModel):\n",
    "    def __init__(self, opt):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.opt.training_media_path = os.path.join(self.opt.dir_name, \"training_media\")\n",
    "        self.dataset_train = None\n",
    "        self.build_network()\n",
    "        self.build_optimizer()\n",
    "        self.build_losses()\n",
    "        self.init_log()\n",
    "        self.colormap = mesh_processor.ColorMap()\n",
    "\n",
    "        self.flags = EasyDict()\n",
    "        self.flags.train = False\n",
    "        self.flags.media_count = 0\n",
    "\n",
    "        self.iteration = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "    def init_log(self):\n",
    "        self.log_path = os.path.join(self.opt.log_path, self.opt.name, 'summary')\n",
    "        if not os.path.exists(self.log_path):\n",
    "            os.makedirs(self.log_path)\n",
    "        self.log_name = os.path.join(self.opt.log_path, self.opt.name, 'loss_log.txt')\n",
    "    \n",
    "    def log_start_train(self):\n",
    "        with open(self.log_name, \"a\") as log_file:\n",
    "            now = time.strftime(\"%c\")\n",
    "            log_file.write('================ Training Loss (%s) ================\\n' % now)\n",
    "\n",
    "    def increment_iteration(self):\n",
    "        self.iteration = self.iteration + 1\n",
    "    def reset_iteration(self):\n",
    "        self.iteration = 0\n",
    "    def increment_epoch(self):\n",
    "        self.epoch = self.epoch + 1\n",
    "    def reset_epoch(self):\n",
    "        self.epoch = self.opt.start_epoch\n",
    "\n",
    "    def print_iteration_stats(self, loss):\n",
    "        \"\"\"\n",
    "        print stats at each iteration\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        ellpased_time = current_time - self.start_train_time\n",
    "        total_time_estimated = self.opt.nepoch * (self.opt.len_dataset / self.opt.batch_size) * ellpased_time / (\n",
    "                0.00001 + self.iteration + 1.0 * self.epoch * self.opt.len_dataset / self.opt.batch_size)  # regle de 3\n",
    "        ETL = total_time_estimated - ellpased_time\n",
    "        print(\n",
    "            f\"\\r[\"\n",
    "            + colored(f\"{self.epoch}\", \"cyan\")\n",
    "            + f\": \"\n",
    "            + colored(f\"{self.iteration}\", \"red\")\n",
    "            + \"/\"\n",
    "            + colored(f\"{int(self.opt.len_dataset / self.opt.batch_size)}\", \"red\")\n",
    "            + \"] chamfer train loss:  \"\n",
    "            + colored(f\"{loss.item()} \", \"yellow\")\n",
    "            + colored(f\"Ellapsed Time: {ellpased_time / 60 / 60}h \", \"cyan\")\n",
    "            + colored(f\"ETL: {ETL / 60 / 60}h\", \"red\"),\n",
    "            end=\"\",\n",
    "        )\n",
    "\n",
    "    def learning_rate_scheduler(self):\n",
    "        \"\"\"\n",
    "        Defines the learning rate schedule\n",
    "        \"\"\"\n",
    "        # Warm-up following https://arxiv.org/pdf/1706.02677.pdf\n",
    "        if len(self.next_learning_rates) > 0:\n",
    "            next_learning_rate = self.next_learning_rates.pop()\n",
    "            print(f\"warm-up learning rate {next_learning_rate}\")\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = next_learning_rate\n",
    "\n",
    "        # Learning rate decay\n",
    "        if self.epoch == self.opt.lr_decay_1:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"First learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n",
    "        if self.epoch == self.opt.lr_decay_2:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"Second learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n",
    "        if self.epoch == self.opt.lr_decay_3:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"Third learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n",
    "            \n",
    "    def demo(self, data1, demo_path, data2=None):\n",
    "        \"\"\"\n",
    "        This function takes an image or pointcloud path as input and save the mesh infered by Atlasnet\n",
    "        Extension supported are ply npy obg and png\n",
    "        :return: path to the generated mesh\n",
    "        \"\"\"\n",
    "        # ext = demo_path.split('.')[-1]\n",
    "        # self.data = self.datasets.dataset_train.load(demo_path)\n",
    "        self.data = data1\n",
    "        self.data = EasyDict(self.data)\n",
    "\n",
    "        if data2 is None:\n",
    "            data2 = data1\n",
    "\n",
    "        #prepare normalization\n",
    "        get_normalization = EasyDict(data2)\n",
    "\n",
    "        \n",
    "        self.make_network_input()\n",
    "        mesh = self.network.module.generate_mesh(self.data.network_input)\n",
    "        if get_normalization.operation is not None:\n",
    "            # Undo any normalization that was used to preprocess the input.\n",
    "            vertices = torch.from_numpy(mesh.vertices).clone().unsqueeze(0)\n",
    "            get_normalization.operation.invert()\n",
    "            unnormalized_vertices = get_normalization.operation.apply(vertices)\n",
    "            mesh = pymesh.form_mesh(vertices=unnormalized_vertices.squeeze().numpy(), faces=mesh.faces)\n",
    "\n",
    "        if self.opt.demo:\n",
    "            path = demo_path.split('.')\n",
    "            path[-2] += \"AtlasnetReconstruction\"\n",
    "            path[-1] = \"ply\"\n",
    "            path = \".\".join(path)\n",
    "        else:\n",
    "            path = '/'.join([self.log_path, str(self.flags.media_count)]) + \".ply\"\n",
    "            self.flags.media_count += 1\n",
    "\n",
    "        print(f\"Atlasnet generated mesh at {path}!\")\n",
    "        mesh_processor.save(mesh, path, self.colormap)\n",
    "        return path\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New MLP decoder : hidden size 512, num_layers 2, activation relu\n",
      "\u001b[33mNo network weights to reload!\u001b[0m\n",
      "log/test_code/summary\n",
      "[\u001b[36m0\u001b[0m: \u001b[31m1\u001b[0m/\u001b[31m364\u001b[0m] chamfer train loss:  \u001b[33m0.12231758236885071 \u001b[0m\u001b[36mEllapsed Time: 0.00023219810591803655h \u001b[0m\u001b[31mETL: 12.705956467290983h\u001b[0mAtlasnet generated mesh at log/test_code/summary/0.ply!\n"
     ]
    }
   ],
   "source": [
    "opt = EasyDict(opt)\n",
    "opt.len_dataset = Dataset.datasets.len_dataset\n",
    "opt.env = opt.env + opt.dir_name.split('/')[-1]\n",
    "mod = Trainer(opt)\n",
    "mod.start_train_time = time.time()\n",
    "\n",
    "print(mod.log_path)\n",
    "\n",
    "mod.flags.train = True\n",
    "if not mod.opt.no_learning:\n",
    "    mod.network.train()\n",
    "else:\n",
    "    mod.network.eval()\n",
    "mod.learning_rate_scheduler()\n",
    "mod.reset_iteration()\n",
    "for i in range(mod.opt.loop_per_epoch):\n",
    "    iterator = Dataset.datasets.dataloader_train.__iter__()\n",
    "    mod.reset_iteration()\n",
    "    mod.log_start_train()\n",
    "    for item in iterator:\n",
    "        mod.increment_iteration()\n",
    "        mod.data = EasyDict(item)\n",
    "        mod.data.points = mod.data.points.to(mod.opt.device)\n",
    "        if Dataset.datasets.data_augmenter is not None and not Dataset.opt.SVR:\n",
    "            Dataset.datasets.data_augmenter(Dataset.data.points)\n",
    "        mod.train_iteration()\n",
    "        # 利用demo函数检查结果 生成的ply文件保存在mod.log_path处\n",
    "        demo_path = mod.data.image_path[0]\n",
    "        demo_path = demo_path+'/01.png'\n",
    "        demo_data = Dataset.datasets.dataset_train.load(demo_path)\n",
    "        with torch.no_grad():\n",
    "            mod.demo(EasyDict(demo_data), demo_path)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New MLP decoder : hidden size 512, num_layers 2, activation relu\n",
      "\u001b[33mNo network weights to reload!\u001b[0m\n",
      "log/test_code/summary\n",
      "[\u001b[36m0\u001b[0m: \u001b[31m1\u001b[0m/\u001b[31m364\u001b[0m] chamfer train loss:  \u001b[33m0.33630669116973877 \u001b[0m\u001b[36mEllapsed Time: 0.00020082546605004203h \u001b[0m\u001b[31mETL: 10.989235330179536h\u001b[0m"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_700/1219550354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdemo_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEasyDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_700/606045031.py\u001b[0m in \u001b[0;36mdemo\u001b[0;34m(self, data1, demo_path, data2)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_network_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mget_normalization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;31m# Undo any normalization that was used to preprocess the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/model/model.py\u001b[0m in \u001b[0;36mgenerate_mesh\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/model/atlasnet.py\u001b[0m in \u001b[0;36mgenerate_mesh\u001b[0;34m(self, latent_vector)\u001b[0m\n\u001b[1;32m     73\u001b[0m         output_meshes = [pymesh.form_mesh(vertices=output_points[i].transpose(1, 0).contiguous().cpu().numpy(),\n\u001b[1;32m     74\u001b[0m                                           faces=self.template[i].mesh.faces)\n\u001b[0;32m---> 75\u001b[0;31m                          for i in range(self.opt.nb_primitives)]\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Deform return the deformed pointcloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/model/atlasnet.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m         output_meshes = [pymesh.form_mesh(vertices=output_points[i].transpose(1, 0).contiguous().cpu().numpy(),\n\u001b[1;32m     74\u001b[0m                                           faces=self.template[i].mesh.faces)\n\u001b[0;32m---> 75\u001b[0;31m                          for i in range(self.opt.nb_primitives)]\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Deform return the deformed pointcloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "opt = EasyDict(opt)\n",
    "opt.len_dataset = Dataset.datasets.len_dataset\n",
    "opt.env = opt.env + opt.dir_name.split('/')[-1]\n",
    "mod = Trainer(opt)\n",
    "mod.start_train_time = time.time()\n",
    "\n",
    "print(mod.log_path)\n",
    "\n",
    "mod.flags.train = False\n",
    "mod.network.eval()\n",
    "mod.learning_rate_scheduler()\n",
    "mod.reset_iteration()\n",
    "for i in range(mod.opt.loop_per_epoch):\n",
    "    iterator = Dataset.datasets.dataloader_train.__iter__()\n",
    "    mod.reset_iteration()\n",
    "    mod.log_start_train()\n",
    "    for item in iterator:\n",
    "        mod.increment_iteration()\n",
    "        mod.data = EasyDict(item)\n",
    "        mod.data.points = mod.data.points.to(mod.opt.device)\n",
    "        if Dataset.datasets.data_augmenter is not None and not Dataset.opt.SVR:\n",
    "            Dataset.datasets.data_augmenter(Dataset.data.points)\n",
    "        mod.train_iteration()\n",
    "        # print(mod.data)\n",
    "        demo_path = mod.data.image_path[0]\n",
    "        demo_path = demo_path+'/01.png'\n",
    "        demo_data = Dataset.datasets.dataset_train.load(demo_path)\n",
    "        with torch.no_grad():\n",
    "            mod.demo(EasyDict(demo_data), demo_path)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc8c60f99e2e962c0e4a3e9c9f27c1bb5f2a586f6d03b97348d9b6648bd2cf92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
