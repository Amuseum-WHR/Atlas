{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "opt = {\"normalization\": \"UnitBall\", \n",
    "            \"class_choice\": [\"plane\"], \n",
    "            \"SVR\": True, \n",
    "            \"sample\": True, \n",
    "            \"npoints\": 2500, \n",
    "            \"number_points\": 2500, \n",
    "            \"shapenet13\": True, \n",
    "            \"demo\": False, \n",
    "            \"data_augmentation_axis_rotation\": True,\n",
    "            \"data_augmentation_random_flips\": False, \n",
    "            \"batch_size\": 32, \"workers\": 0, \n",
    "            \"batch_size_test\": 32, \n",
    "            \"random_translation\": False, \n",
    "            \"anisotropic_scaling\": False, \n",
    "            \"random_rotation\": False, # 以上为加载dataset需要\n",
    "            \"multi_gpu\": [0],\n",
    "            \"bottleneck_size\": 1024,\n",
    "            \"nb_primitives\": 1,\n",
    "            \"number_points\": 2500,\n",
    "            \"number_points_eval\": 2500,\n",
    "            \"remove_all_batchNorms\": False,\n",
    "            \"template_type\": \"SPHERE\",\n",
    "            \"dim_template\": 3,\n",
    "            \"hidden_neurons\": 512,\n",
    "            \"num_layers\": 2,\n",
    "            \"activation\" : \"relu\",\n",
    "            \"reload_model_path\": \"\",\n",
    "            \"reload_decoder_path\": \"\",\n",
    "            \"train_only_encoder\": False,\n",
    "            \"lrate\": 0.001,\n",
    "            \"no_learning\": False,\n",
    "            \"nepoch\": 150,\n",
    "            \"reload_optimizer_path\": \"\", #下面两个是log信息\n",
    "            \"log_path\": \"log\",\n",
    "            \"name\": \"test_code\",\n",
    "            \"loop_per_epoch\": 1,\n",
    "            \"lr_decay_1\": 120,\n",
    "            \"lr_decay_2\": 140,\n",
    "            \"lr_decay_3\": 145,\n",
    "            \"visdom_port\": 8890,\n",
    "            \"http_port\": 8891,\n",
    "            \"env\": \"Atlasnet\",\n",
    "            \"dir_name\": \"\"}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDataset normalization : UnitBall\u001b[0m\n",
      "\u001b[31mCreate Shapenet Dataset...\u001b[0m\n",
      "    category \u001b[33m02691156\u001b[0m  \u001b[36mairplane\u001b[0m Number Files :\u001b[33m3236\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/env1/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    category \u001b[33m02828884\u001b[0m  \u001b[36mbench\u001b[0m Number Files :\u001b[33m1452\u001b[0m\n",
      "    category \u001b[33m02933112\u001b[0m  \u001b[36mcabinet\u001b[0m Number Files :\u001b[33m1257\u001b[0m\n",
      "    category \u001b[33m02958343\u001b[0m  \u001b[36mcar\u001b[0m Number Files :\u001b[33m5996\u001b[0m\n",
      "    category \u001b[33m03001627\u001b[0m  \u001b[36mchair\u001b[0m Number Files :\u001b[33m5422\u001b[0m\n",
      "    category \u001b[33m03211117\u001b[0m  \u001b[36mdisplay\u001b[0m Number Files :\u001b[33m876\u001b[0m\n",
      "    category \u001b[33m03636649\u001b[0m  \u001b[36mlamp\u001b[0m Number Files :\u001b[33m1854\u001b[0m\n",
      "    category \u001b[33m03691459\u001b[0m  \u001b[36mloudspeaker\u001b[0m Number Files :\u001b[33m1294\u001b[0m\n",
      "    category \u001b[33m04090263\u001b[0m  \u001b[36mrifle\u001b[0m Number Files :\u001b[33m1897\u001b[0m\n",
      "    category \u001b[33m04256520\u001b[0m  \u001b[36msofa\u001b[0m Number Files :\u001b[33m2538\u001b[0m\n",
      "    category \u001b[33m04379243\u001b[0m  \u001b[36mtable\u001b[0m Number Files :\u001b[33m6807\u001b[0m\n",
      "    category \u001b[33m04401088\u001b[0m  \u001b[36mtelephone\u001b[0m Number Files :\u001b[33m841\u001b[0m\n",
      "    category \u001b[33m04530566\u001b[0m  \u001b[36mvessel\u001b[0m Number Files :\u001b[33m1551\u001b[0m\n",
      "\u001b[31mReload dataset : /mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/cache/UnitBallTrueairplane_bench_cabinet_car_chair_display_lamp_loudspeaker_rifle_sofa_table_telephone_vessel\u001b[0m\n",
      "\u001b[31mDataset Size: 11674\u001b[0m\n",
      "\u001b[31mDataset normalization : UnitBall\u001b[0m\n",
      "\u001b[31mCreate Shapenet Dataset...\u001b[0m\n",
      "    category \u001b[33m02691156\u001b[0m  \u001b[36mairplane\u001b[0m Number Files :\u001b[33m809\u001b[0m\n",
      "    category \u001b[33m02828884\u001b[0m  \u001b[36mbench\u001b[0m Number Files :\u001b[33m364\u001b[0m\n",
      "    category \u001b[33m02933112\u001b[0m  \u001b[36mcabinet\u001b[0m Number Files :\u001b[33m315\u001b[0m\n",
      "    category \u001b[33m02958343\u001b[0m  \u001b[36mcar\u001b[0m Number Files :\u001b[33m1500\u001b[0m\n",
      "    category \u001b[33m03001627\u001b[0m  \u001b[36mchair\u001b[0m Number Files :\u001b[33m1356\u001b[0m\n",
      "    category \u001b[33m03211117\u001b[0m  \u001b[36mdisplay\u001b[0m Number Files :\u001b[33m219\u001b[0m\n",
      "    category \u001b[33m03636649\u001b[0m  \u001b[36mlamp\u001b[0m Number Files :\u001b[33m464\u001b[0m\n",
      "    category \u001b[33m03691459\u001b[0m  \u001b[36mloudspeaker\u001b[0m Number Files :\u001b[33m324\u001b[0m\n",
      "    category \u001b[33m04090263\u001b[0m  \u001b[36mrifle\u001b[0m Number Files :\u001b[33m475\u001b[0m\n",
      "    category \u001b[33m04256520\u001b[0m  \u001b[36msofa\u001b[0m Number Files :\u001b[33m635\u001b[0m\n",
      "    category \u001b[33m04379243\u001b[0m  \u001b[36mtable\u001b[0m Number Files :\u001b[33m1702\u001b[0m\n",
      "    category \u001b[33m04401088\u001b[0m  \u001b[36mtelephone\u001b[0m Number Files :\u001b[33m211\u001b[0m\n",
      "    category \u001b[33m04530566\u001b[0m  \u001b[36mvessel\u001b[0m Number Files :\u001b[33m388\u001b[0m\n",
      "\u001b[31mReload dataset : /mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/cache/UnitBallFalseairplane_bench_cabinet_car_chair_display_lamp_loudspeaker_rifle_sofa_table_telephone_vessel\u001b[0m\n",
      "\u001b[31mDataset Size: 2921\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from dataset.trainer_dataset import TrainerDataset\n",
    "Dataset = TrainerDataset()\n",
    "Dataset.opt = EasyDict(opt)\n",
    "Dataset.build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded compiled 3D CUDA chamfer distance\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# 注意metro部分需要修改地址\n",
    "import os\n",
    "import time\n",
    "from training.trainer_loss import TrainerLoss\n",
    "from model.trainer_model import TrainerModel\n",
    "from dataset.trainer_dataset import TrainerDataset\n",
    "from training.trainer_iteration import TrainerIteration\n",
    "from dataset.trainer_dataset import TrainerDataset\n",
    "from termcolor import colored\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer(TrainerLoss, TrainerIteration, TrainerModel):\n",
    "    def __init__(self, opt):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.dataset_train = None\n",
    "        self.build_network()\n",
    "        self.build_optimizer()\n",
    "        self.build_losses()\n",
    "        self.init_log()\n",
    "\n",
    "        self.flags = EasyDict()\n",
    "        self.flags.train = False\n",
    "\n",
    "        self.iteration = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "    def init_log(self):\n",
    "        self.log_path = os.path.join(self.opt.log_path, self.opt.name, 'summary')\n",
    "        if not os.path.exists(self.log_path):\n",
    "            os.makedirs(self.log_path)\n",
    "        self.log_name = os.path.join(self.opt.log_path, self.opt.name, 'loss_log.txt')\n",
    "    \n",
    "    def log_start_train(self):\n",
    "        with open(self.log_name, \"a\") as log_file:\n",
    "            now = time.strftime(\"%c\")\n",
    "            log_file.write('================ Training Loss (%s) ================\\n' % now)\n",
    "\n",
    "    def increment_iteration(self):\n",
    "        self.iteration = self.iteration + 1\n",
    "    def reset_iteration(self):\n",
    "        self.iteration = 0\n",
    "    def increment_epoch(self):\n",
    "        self.epoch = self.epoch + 1\n",
    "    def reset_epoch(self):\n",
    "        self.epoch = self.opt.start_epoch\n",
    "\n",
    "    def print_iteration_stats(self, loss):\n",
    "        \"\"\"\n",
    "        print stats at each iteration\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        ellpased_time = current_time - self.start_train_time\n",
    "        total_time_estimated = self.opt.nepoch * (self.opt.len_dataset / self.opt.batch_size) * ellpased_time / (\n",
    "                0.00001 + self.iteration + 1.0 * self.epoch * self.opt.len_dataset / self.opt.batch_size)  # regle de 3\n",
    "        ETL = total_time_estimated - ellpased_time\n",
    "        print(\n",
    "            f\"\\r[\"\n",
    "            + colored(f\"{self.epoch}\", \"cyan\")\n",
    "            + f\": \"\n",
    "            + colored(f\"{self.iteration}\", \"red\")\n",
    "            + \"/\"\n",
    "            + colored(f\"{int(self.opt.len_dataset / self.opt.batch_size)}\", \"red\")\n",
    "            + \"] chamfer train loss:  \"\n",
    "            + colored(f\"{loss.item()} \", \"yellow\")\n",
    "            + colored(f\"Ellapsed Time: {ellpased_time / 60 / 60}h \", \"cyan\")\n",
    "            + colored(f\"ETL: {ETL / 60 / 60}h\", \"red\"),\n",
    "            end=\"\",\n",
    "        )\n",
    "\n",
    "    def learning_rate_scheduler(self):\n",
    "        \"\"\"\n",
    "        Defines the learning rate schedule\n",
    "        \"\"\"\n",
    "        # Warm-up following https://arxiv.org/pdf/1706.02677.pdf\n",
    "        if len(self.next_learning_rates) > 0:\n",
    "            next_learning_rate = self.next_learning_rates.pop()\n",
    "            print(f\"warm-up learning rate {next_learning_rate}\")\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = next_learning_rate\n",
    "\n",
    "        # Learning rate decay\n",
    "        if self.epoch == self.opt.lr_decay_1:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"First learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n",
    "        if self.epoch == self.opt.lr_decay_2:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"Second learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n",
    "        if self.epoch == self.opt.lr_decay_3:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"Third learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New MLP decoder : hidden size 512, num_layers 2, activation relu\n",
      "\u001b[33mNo network weights to reload!\u001b[0m\n",
      "[\u001b[36m0\u001b[0m: \u001b[31m1\u001b[0m/\u001b[31m364\u001b[0m] chamfer train loss:  \u001b[33m0.1549694538116455 \u001b[0m\u001b[36mEllapsed Time: 0.0006983827220069037h \u001b[0m\u001b[31mETL: 38.21573146880101h\u001b[0m"
     ]
    }
   ],
   "source": [
    "opt = EasyDict(opt)\n",
    "opt.len_dataset = Dataset.datasets.len_dataset\n",
    "opt.env = opt.env + opt.dir_name.split('/')[-1]\n",
    "mod = Trainer(opt)\n",
    "mod.start_train_time = time.time()\n",
    "\n",
    "mod.flags.train = True\n",
    "if not mod.opt.no_learning:\n",
    "    mod.network.train()\n",
    "else:\n",
    "    mod.network.eval()\n",
    "mod.learning_rate_scheduler()\n",
    "mod.reset_iteration()\n",
    "for i in range(mod.opt.loop_per_epoch):\n",
    "    iterator = Dataset.datasets.dataloader_train.__iter__()\n",
    "    mod.reset_iteration()\n",
    "    mod.log_start_train()\n",
    "    for item in iterator:\n",
    "        mod.increment_iteration()\n",
    "        mod.data = EasyDict(item)\n",
    "        mod.data.points = mod.data.points.to(mod.opt.device)\n",
    "        if Dataset.datasets.data_augmenter is not None and not Dataset.opt.SVR:\n",
    "            Dataset.datasets.data_augmenter(Dataset.data.points)\n",
    "        mod.train_iteration()\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('env1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc8c60f99e2e962c0e4a3e9c9f27c1bb5f2a586f6d03b97348d9b6648bd2cf92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
