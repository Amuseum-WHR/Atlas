{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "# opt的使用请参照auxiliary/argument_parser.py中opt的说明\n",
    "opt = {\"normalization\": \"UnitBall\",\n",
    "            \"class_choice\": [\"plane\"], \n",
    "            \"SVR\": True, \n",
    "            \"sample\": True, \n",
    "            \"npoints\": 2500, \n",
    "            \"number_points\": 2500, \n",
    "            \"shapenet13\": True, \n",
    "            \"demo\": False, \n",
    "            \"data_augmentation_axis_rotation\": True,\n",
    "            \"data_augmentation_random_flips\": False, \n",
    "            \"batch_size\": 32, \n",
    "            \"workers\": 0, \n",
    "            \"batch_size_test\": 32, \n",
    "            \"random_translation\": False, \n",
    "            \"anisotropic_scaling\": False, \n",
    "            \"random_rotation\": False, # 以上为加载dataset需要\n",
    "            \"multi_gpu\": [0],\n",
    "            \"bottleneck_size\": 1024,\n",
    "            \"nb_primitives\": 1,\n",
    "            \"number_points\": 2500,\n",
    "            \"number_points_eval\": 2500,\n",
    "            \"remove_all_batchNorms\": False,\n",
    "            \"template_type\": \"SPHERE\",\n",
    "            \"dim_template\": 3,\n",
    "            \"hidden_neurons\": 512,\n",
    "            \"num_layers\": 2,\n",
    "            \"activation\" : \"relu\",\n",
    "            \"reload_model_path\": \"\",\n",
    "            \"reload_decoder_path\": \"\",\n",
    "            \"train_only_encoder\": False,\n",
    "            \"lrate\": 0.001,\n",
    "            \"no_learning\": False,\n",
    "            \"nepoch\": 150,\n",
    "            \"reload_optimizer_path\": \"\", #下面两个是log信息\n",
    "            \"log_path\": \"log\",\n",
    "            \"name\": \"test_code\",\n",
    "            \"loop_per_epoch\": 1,\n",
    "            \"lr_decay_1\": 120,\n",
    "            \"lr_decay_2\": 140,\n",
    "            \"lr_decay_3\": 145,\n",
    "            \"visdom_port\": 8890,\n",
    "            \"http_port\": 8891,\n",
    "            \"env\": \"Atlasnet\",\n",
    "            \"dir_name\": \"\"}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDataset normalization : UnitBall\u001b[0m\n",
      "\u001b[31mCreate Shapenet Dataset...\u001b[0m\n",
      "\u001b[31mReload dataset : /mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/cache/UnitBallTrueairplane_bench_cabinet_car_chair_display_lamp_loudspeaker_rifle_sofa_table_telephone_vessel\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/env1/lib/python3.7/site-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDataset Size: 11674\u001b[0m\n",
      "\u001b[31mDataset normalization : UnitBall\u001b[0m\n",
      "\u001b[31mCreate Shapenet Dataset...\u001b[0m\n",
      "\u001b[31mReload dataset : /mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/cache/UnitBallFalseairplane_bench_cabinet_car_chair_display_lamp_loudspeaker_rifle_sofa_table_telephone_vessel\u001b[0m\n",
      "\u001b[31mDataset Size: 2921\u001b[0m\n",
      "hello\n",
      "{'pointcloud_path': '/mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/ShapeNetV1PointCloud/02691156/103c9e43cdf6501c62b600da24e0965.points.ply.npy', 'image_path': '/mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/AtlasNet-master/data/ShapeNetV1Renderings/02691156/103c9e43cdf6501c62b600da24e0965/rendering', 'name': '103c9e43cdf6501c62b600da24e0965.points.ply.npy', 'category': '02691156', 'points': tensor([[-0.0867, -0.0114, -0.3826],\n",
      "        [-0.0384,  0.0483,  0.0321],\n",
      "        [ 0.1717, -0.0233, -0.1766],\n",
      "        ...,\n",
      "        [ 0.5322,  0.0694, -0.0442],\n",
      "        [-0.4537,  0.0842, -0.0201],\n",
      "        [ 0.9903, -0.0357, -0.0106]]), 'image': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_897/2470527433.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mDataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEasyDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/d/Mr.Wang/大学/大三上/计算机视觉/Atlas/dataset/trainer_dataset.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m                                                                          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                                          \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                                                          num_workers=int(self.opt.workers))\n\u001b[0m\u001b[1;32m     31\u001b[0m             self.datasets.dataloader_test = torch.utils.data.DataLoader(self.datasets.dataset_test,\n\u001b[1;32m     32\u001b[0m                                                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env1/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m--> 108\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "from dataset.trainer_dataset import TrainerDataset\n",
    "Dataset = TrainerDataset()\n",
    "Dataset.opt = EasyDict(opt)\n",
    "Dataset.build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded compiled 3D CUDA chamfer distance\n",
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "# 注意metro部分需要修改地址\n",
    "import os\n",
    "import time\n",
    "from training.trainer_loss import TrainerLoss\n",
    "from model.trainer_model import TrainerModel\n",
    "from dataset.trainer_dataset import TrainerDataset\n",
    "from training.trainer_iteration import TrainerIteration\n",
    "from dataset.trainer_dataset import TrainerDataset\n",
    "from termcolor import colored\n",
    "import torch.optim as optim\n",
    "\n",
    "class Trainer(TrainerLoss, TrainerIteration, TrainerModel):\n",
    "    def __init__(self, opt):\n",
    "        super(Trainer, self).__init__()\n",
    "        self.opt = opt\n",
    "        self.dataset_train = None\n",
    "        self.build_network()\n",
    "        self.build_optimizer()\n",
    "        self.build_losses()\n",
    "        self.init_log()\n",
    "\n",
    "        self.flags = EasyDict()\n",
    "        self.flags.train = False\n",
    "\n",
    "        self.iteration = 0\n",
    "        self.epoch = 0\n",
    "\n",
    "    def init_log(self):\n",
    "        self.log_path = os.path.join(self.opt.log_path, self.opt.name, 'summary')\n",
    "        if not os.path.exists(self.log_path):\n",
    "            os.makedirs(self.log_path)\n",
    "        self.log_name = os.path.join(self.opt.log_path, self.opt.name, 'loss_log.txt')\n",
    "    \n",
    "    def log_start_train(self):\n",
    "        with open(self.log_name, \"a\") as log_file:\n",
    "            now = time.strftime(\"%c\")\n",
    "            log_file.write('================ Training Loss (%s) ================\\n' % now)\n",
    "\n",
    "    def increment_iteration(self):\n",
    "        self.iteration = self.iteration + 1\n",
    "    def reset_iteration(self):\n",
    "        self.iteration = 0\n",
    "    def increment_epoch(self):\n",
    "        self.epoch = self.epoch + 1\n",
    "    def reset_epoch(self):\n",
    "        self.epoch = self.opt.start_epoch\n",
    "\n",
    "    def print_iteration_stats(self, loss):\n",
    "        \"\"\"\n",
    "        print stats at each iteration\n",
    "        \"\"\"\n",
    "        current_time = time.time()\n",
    "        ellpased_time = current_time - self.start_train_time\n",
    "        total_time_estimated = self.opt.nepoch * (self.opt.len_dataset / self.opt.batch_size) * ellpased_time / (\n",
    "                0.00001 + self.iteration + 1.0 * self.epoch * self.opt.len_dataset / self.opt.batch_size)  # regle de 3\n",
    "        ETL = total_time_estimated - ellpased_time\n",
    "        print(\n",
    "            f\"\\r[\"\n",
    "            + colored(f\"{self.epoch}\", \"cyan\")\n",
    "            + f\": \"\n",
    "            + colored(f\"{self.iteration}\", \"red\")\n",
    "            + \"/\"\n",
    "            + colored(f\"{int(self.opt.len_dataset / self.opt.batch_size)}\", \"red\")\n",
    "            + \"] chamfer train loss:  \"\n",
    "            + colored(f\"{loss.item()} \", \"yellow\")\n",
    "            + colored(f\"Ellapsed Time: {ellpased_time / 60 / 60}h \", \"cyan\")\n",
    "            + colored(f\"ETL: {ETL / 60 / 60}h\", \"red\"),\n",
    "            end=\"\",\n",
    "        )\n",
    "\n",
    "    def learning_rate_scheduler(self):\n",
    "        \"\"\"\n",
    "        Defines the learning rate schedule\n",
    "        \"\"\"\n",
    "        # Warm-up following https://arxiv.org/pdf/1706.02677.pdf\n",
    "        if len(self.next_learning_rates) > 0:\n",
    "            next_learning_rate = self.next_learning_rates.pop()\n",
    "            print(f\"warm-up learning rate {next_learning_rate}\")\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = next_learning_rate\n",
    "\n",
    "        # Learning rate decay\n",
    "        if self.epoch == self.opt.lr_decay_1:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"First learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n",
    "        if self.epoch == self.opt.lr_decay_2:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"Second learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)\n",
    "        if self.epoch == self.opt.lr_decay_3:\n",
    "            self.opt.lrate = self.opt.lrate / 10.0\n",
    "            print(f\"Third learning rate decay {self.opt.lrate}\")\n",
    "            self.optimizer = optim.Adam(self.network.parameters(), lr=self.opt.lrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New MLP decoder : hidden size 512, num_layers 2, activation relu\n",
      "\u001b[33mNo network weights to reload!\u001b[0m\n",
      "[\u001b[36m0\u001b[0m: \u001b[31m1\u001b[0m/\u001b[31m364\u001b[0m] chamfer train loss:  \u001b[33m0.1549694538116455 \u001b[0m\u001b[36mEllapsed Time: 0.0006983827220069037h \u001b[0m\u001b[31mETL: 38.21573146880101h\u001b[0m"
     ]
    }
   ],
   "source": [
    "opt = EasyDict(opt)\n",
    "opt.len_dataset = Dataset.datasets.len_dataset\n",
    "opt.env = opt.env + opt.dir_name.split('/')[-1]\n",
    "mod = Trainer(opt)\n",
    "mod.start_train_time = time.time()\n",
    "\n",
    "mod.flags.train = True\n",
    "if not mod.opt.no_learning:\n",
    "    mod.network.train()\n",
    "else:\n",
    "    mod.network.eval()\n",
    "mod.learning_rate_scheduler()\n",
    "mod.reset_iteration()\n",
    "for i in range(mod.opt.loop_per_epoch):\n",
    "    iterator = Dataset.datasets.dataloader_train.__iter__()\n",
    "    mod.reset_iteration()\n",
    "    mod.log_start_train()\n",
    "    for item in iterator:\n",
    "        mod.increment_iteration()\n",
    "        mod.data = EasyDict(item)\n",
    "        mod.data.points = mod.data.points.to(mod.opt.device)\n",
    "        if Dataset.datasets.data_augmenter is not None and not Dataset.opt.SVR:\n",
    "            Dataset.datasets.data_augmenter(Dataset.data.points)\n",
    "        mod.train_iteration()\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa0ca4915fdca8b2e2cf6f1b8b0e55d959d18791a209dc1b83c153448ea2ecb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
